




#### 通俗地理解三个范式

　　通俗地理解三个范式，对于数据库设计大有好处。在数据库设计中，为了更好地应用三个范式，就必须通俗地理解三个范式(通俗地理解是够用的理解，并不是最科学最准确的理解)：

　　第一范式：1NF是对属性的原子性约束，要求属性具有原子性，不可再分解;

　　第二范式：2NF是对记录的惟一性约束，要求记录有惟一标识，即实体的惟一性;

　　第三范式：3NF是对字段冗余性的约束，即任何字段不能由其他字段派生出来，它要求字段没有冗余。没有冗余的数据库设计可以做到。但是，没有冗余的数据库未必是最好的数据库，有时为了提高运行效率，就必须降低范式标准，适当保留冗余数据。具体做法是：在概念数据模型设计时遵守第三范式，降低范式标准的工作放到物理数据模型设计时考虑。降低范式就是增加字段，允许冗余。



#### 什么是事务的ACID

1)原子性(Atomic)：事务中各项操作，要么全做要么全不做，任何一项操作的失败都会导致整个事务的失败；

2)一致性(Consistent)：事务结束后系统状态是一致的；

3)隔离性(Isolated)：并发执行的事务彼此无法看到对方的中间状态；

4)持久性(Durable)：事务完成后所做的改动都会被持久化，即使发生灾难性的失败。通过日志和同步备份可以在故障发生后重建数据。

#### B+树

##### B+树的特点

1/每个节点中子节点的个数不能超过 m，也不能小于 m/2；
2/根节点的子节点个数可以不超过 m/2，这是一个例外；
3/m 叉树只存储索引，并不真正存储数据，这个有点儿类似跳表；
4/通过链表将叶子节点串联在一起，这样可以方便的按区间查找；
5/一般情况，根节点会被存储在内存中，其他节点存储在磁盘中。
除了 B+ 树，你可能还听过 B树、B-树。实际上B-树就是B树，其英文翻译都是 B-Tree，这里的 “-”只是一个连接符。
而B树实际上是低版本的B+树，或者说 B+树是B树的改进版。B树跟B+不同点主要集中在这几个地方：

B+ 树索引的所有数据均存储在叶子节点，，而且数据是按照顺序排列的。那么 B+ 树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。而 B 树因为数据分散在各个节点，要实现这一点是很不容易的。

##### B+和B树对比

1/B+树中的节点不存储数据，只是索引，而B树中的节点存储数据.
2/B树中的叶子节点并不需要链表来串联
3/也就是说，B树只是一个每个节点的子节点个数不小于m/2的m叉树。

而B+树中间节点没有Data数据，所以同样大小的磁盘页可以容纳更多的节点元素。所以数据量相同的情况下，B+树比B树更加“矮胖“，因此使用的IO查询次数更少。


##### 页

因为内存的易失性。一般情况下，我们都会选择将表中的数据和索引存储在磁盘这种外围设备中。但是和内存相比，从磁盘中读取数据的速度会慢上百倍千倍甚至万倍，所以，我们应当尽量减少从磁盘中读取数据的次数。另外，从磁盘中读取数据时，都是按照磁盘块来读取的，并不是一条一条的读。如果我们能把尽量多的数据放进磁盘块中，那一次磁盘读取操作就会读取更多数据，那我们查找数据的时间也会大幅度降低。如果我们用树这种数据结构作为索引的数据结构，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块。

每个节点称为页，页就是我们上面说的磁盘块，在 MySQL 中数据读取的基本单位都是页，所以我们这里叫做页更符合 MySQL 中索引的底层数据结构。

数据库中页的大小是固定的，InnoDB 中页的默认大小是 16KB。如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的 IO 次数又会再次减少，数据查询的效率也会更快。
另外，B+ 树的阶数是等于键值的数量的，如果我们的 B+ 树一个节点可以存储 1000 个键值，那么 3 层 B+ 树可以存储 1000×1000×1000=10 亿个数据。一般根节点是常驻内存的，所以一般我们查找 10 亿数据，只需要 2 次磁盘 IO。



#### 索引

索引也不是“银弹”，它会让写入数据的效率下降。因为在数据写入过程，会涉及索引的更新，这是索引导致写入变慢的主要原因。正是因为要时刻保证 B+ 树索引是一个 m 叉树，所有，索引的存在会导致数据库写入的速度降低。实际上，删除数据也会变慢。

若索引太多，应用程序的性能可能会受到影响。而索引太少，对查询性能又会产生影响，要找到一个平衡点，这对应用程序的性能至关重要。

##### 聚集索引 VS 非聚集索引

①聚集索引（聚簇索引clustered index）：以 InnoDB 作为存储引擎的表，表中的数据都会有一个主键，即使你不创建主键，系统也会帮你创建一个隐式的主键。
这是因为 InnoDB 是把数据存放在 B+ 树中的，而 B+ 树的键值就是主键，这种以主键作为 B+ 树索引的键值而构建的 B+ 树索引，我们称之为聚集索引。
②非聚集索引（辅助索引，Secondary Index，也称为非聚集索引）：以主键以外的列值作为键值构建的 B+ 树索引，我们称之为非聚集索引。
非聚集索引与聚集索引的区别在于非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键，想要查找数据我们还需要根据主键再去聚集索引中进行查找，这个再根据聚集索引查找数据的过程，我们称为回表。
叶子节点除了包含键值以外，每个叶子节点中的索引行中还包含一个书签（bookmark）。该书签用来告诉InnoDB存储引擎去哪里可以找到与索引相对应的行数据。由于InnoDB存储引擎是索引组织表，因此InnoDB存储引擎的辅助索引的书签就是相应行数据的聚集索引键。
辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引，但只能有一个聚集索引。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶子级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录。

**聚集索引**

1. 纪录的索引顺序与物理顺序相同，因此更适合between and和order by操作
2. 叶子结点直接对应数据从中间级的索引页的索引行直接对应数据页
3. 每张表只能创建一个聚集索引

**非聚集索引**

1. 索引顺序和物理顺序无关
2. 叶子结点不直接指向数据页
3. 每张表可以有多个非聚集索引，需要更多磁盘和内容，多个索引会影响insert和update的速度

##### 联合索引

**最左匹配原则**：在通过联合索引检索数据时，从索引中最左边的列开始，一直向右匹配，如果遇到范围查询(>、<、between、like等)，就停止后边的匹配。使用函数、运算表达式及类型隐式转换等，也无法使用索引。

假如对字段 (a, b, c) 建立联合索引

```sql
where b = xxx and a = xxx
where a = xxx and c = xxx and b = xxx
```

虽然b和a的顺序换了，但是mysql中的优化器会帮助我们调整顺序。

用到联合索引的一部分

```sql
where a = xxx and c = xxx   可以用到 a 列的索引，用不到 c 列索引。
where a like 'xxx%' and b = xxx 可以用到 a 列的索引，用不到 b 列的索引。
where a > xxx and b = xxx 可以用到 a 列的索引，用不到 b 列的索引。
```

##### **索引覆盖**

建立了联合索引后，直接在索引中就可以得到查询结果，从而不需要回表查询聚簇索引中的行数据信息。
索引覆盖可以带来很多的好处：

- 辅助索引不包含行数据的所有信息，故其大小远小于聚簇索引，因此可以减少大量的IO操作。
- 索引覆盖只需要扫描一次索引树，不需要回表扫描聚簇索引树，所以性能比回表查询要高。
- 索引中列值是按顺序存储的，索引覆盖能避免范围查询回表带来的大量随机IO操作。

##### 索引下推

是索引下推是 MySQL 5.6 及以上版本上推出的，用于对查询进行优化。
索引下推是把本应该在 server 层进行筛选的条件，下推到存储引擎层来进行筛选判断，这样能有效减少回表。

举例说明，首先使用联合索引（name，age），现在有这样一个查询语句：

```sql
select *  from t_user where name like 'L%' and age = 17;
```

这条语句从最左匹配原则上来说是不符合的，原因在于只有name用的索引，但是age并没有用到。
**不用索引下推的执行过程：**

```
第一步：利用索引找出name带'L'的数据行：LiLei、Lili、Lisa、Lucy 这四条索引数据
第二步：再根据这四条索引数据中的 id 值，逐一进行回表扫描，从聚簇索引中找到相应的行数据，将找到的行数据返回给 server 层。
第三步：在server层判断age = 17,进行筛选，最终只留下 Lucy 用户的数据信息。
```

**使用索引下推的执行过程：**

```
第一步：利用索引找出name带'L'的数据行：LiLei、Lili、Lisa、Lucy 这四条索引数据
第二步：根据 age = 17 这个条件，对四条索引数据进行判断筛选，最终只留下 Lucy 用户的数据信息。
（注意：这一步不是直接进行回表操作，而是根据 age = 17 这个条件，对四条索引数据进行判断筛选）
第三步：将符合条件的索引对应的 id 进行回表扫描，最终将找到的行数据返回给 server 层。
```

比较二者的第二步我们发现，索引下推的方式极大的减少了回表次数。

**索引下推需要注意的情况：**
下推的前提是索引中有 age 列信息，如果是其它条件，如 gender = 0，这个即使下推下来也没用.





#### 事务隔离级别

##### 脏读

脏读（dirty read），简单来说，就是一个事务在处理过程中读取了另外一个事务未提交的数据。
这种未提交的数据我们称之为脏数据。依据脏数据所做的操作肯能是不正确的。

##### 不可重复读 【同一条数据】

不可重复读（non-repeatable read），是指一个事务范围内，多次查询某个数据，却得到不同的结果。在第一个事务中的两次读取数据之间，由于第二个事务的修改，第一个事务两次读到的数据可能就是不一样的。

**举例**

例1：在事务A中，读取到张三的工资为5000，操作没有完成，事务还没提交。与此同时，事务B把张三的工资改为8000，并提交了事务。随后，在事务A中，再次读取张三的工资，此时工资变为8000。在一个事务中前后两次读取的结果并不致，导致了不可重复读。

例2: 

| 时间点 | 事务A         | 事务B         |
| ------ | ------------- | ------------- |
| 1      | 开启事务A     |               |
| 2      |               | 开启事务B     |
| 3      | 查询余额为100 |               |
| 4      |               | 余额增加至150 |
| 5      | 查询余额为100 |               |
| 6      |               | 提交事务      |
| 7      | 查询余额为150 |               |

脏读和不可重复读的区别是，脏读是某一事务读取了另外一个事务未提交的数据，不可重复读是读取了其他事务提交的数据。

**repeatable read案例**

repeatable read下，如果有2个线程，一个线程1对一条数据修改，读到100+1，另一个线程2读数据读到的是多少？
1、如果线程1未提交，线程2读到的是多少？100
2、如果线程1已提交，线程2读到的是多少？100

##### 幻读(phantom read)【多条数据】

幻读（phantom read），是事务非独立执行时发生的一种现象。

例如事务 T1 对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务 T2 又对这个表中插入了一行数据项为“1”的数据，并且提交给数据库。

而操作事务 T1 的用户如果再查看刚刚修改的数据，会发现数据怎么还是 1？其实这行是从事务 T2 中添加的，就好像产生幻觉一样，这就是发生了幻读。

**举例**

| 时间点 | 事务A                     | 事务B            |
| ------ | ------------------------- | ---------------- |
| 1      | 开启事务A                 |                  |
| 2      |                           | 开启事务B        |
| 3      | 查询id<3的所有记录，共3条 |                  |
| 4      |                           | 插入一条记录id=2 |
| 5      |                           | 提交事务         |
| 6      | 查询id<3的所有记录，共4条 |                  |

##### 隔离级别

为了解决上面可能出现的问题，我们就需要设置隔离级别。ANSI/ISO SQL 定义了 4 种标准隔离级别：Read UnCommitted（读未提交）、Read Commited（读已提交）、Repeatable Read（可重复读）、Serializable（串行化）【未已重串】
Mysql默认的事务隔离级别是可重复读(Repeatable Read)
Oracle的默认隔离级别就是Read Commited

| 隔离级别                     | 脏读 | 不可重复读 | 幻读 |
| ---------------------------- | ---- | ---------- | ---- |
| read uncommitted（未提交读） | √    | √          | √    |
| read committed（提交读）     | ×    | √          | √    |
| repeatable read（可重复读）  | ×    | ×          | √    |
| serialization（可串行化）    | ×    | ×          | ×    |

①  Read uncommitted (读未提交)：最低的事务隔离级别，一个事务还没提交时，它做的变更就能被别的事务看到。
任何情况都无法保证。

②Read committed (读已提交)：保证一个事物**提交后**才能被另外一个事务读取。另外一个事务不能读取该事物未提交的数据。
可避免脏读的发生，但是可能会造成不可重复读。
大多数数据库的默认级别就是 Read committed，比如 Sql Server , Oracle。

③  Repeatable read（可重复读，默认级别）：多次读取同一范围的数据会返回第一次查询的快照，即使其他事务对该数据做了更新修改。事务在执行期间看到的数据前后必须是一致的。
但如果这个事务在读取某个范围内的记录时，其他事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行，这就是幻读。
可避免脏读、不可重复读的发生。但是可能会出现幻读。

④Serializable（串行化）：花费最高代价但最可靠的事务隔离级别。
“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。
事务 100% 隔离，可避免脏读、不可重复读、幻读的发生。

下图中是一个很好的例子，分别解释了四种事务隔离级别下，事务 B 能够读取到的结果。

![](/Users/lidongyue/codes/GitHub/arthur-dy-lee-note/interview/pics/transaction_isolation.jpg)

**再次总结**

读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。
读已提交：别人改数据的事务已经提交，我在我的事务中才能读到。
可重复读：别人改数据的事务已经提交，我在我的事务中也不去读。
串行：我的事务尚未提交，别人就别想改数据。

这 4 种隔离级别，并行性能依次降低，安全性依次提高。

##### 隔离级别的实现

事务的机制是通过**视图（read-view）**来实现的并发版本控制（MVCC），不同的事务隔离级别创建读视图的时间点不同。

- 读未提交是不创建，直接返回记录上的最新值
- 读已提交是每条 SQL 创建读视图，在每个 SQL 语句开始执行的时候创建的。隔离作用域仅限该条 SQL 语句。
- **可重复读是每个事务重建读视图，整个事务存在期间都用这个视图。**
- 串行化隔离级别下直接用加锁的方式来避免并行访问。

这里的视图可以理解为**数据副本**，每次创建视图时，将当前**已持久化的数据**创建副本，后续直接从副本读取，从而达到数据隔离效果。

我们每一次的修改操作，并不是直接对行数据进行操作。

比如我们设置 id 为 3 的行的 A 属性为 10，并不是直接修改表中的数据，而是新加一行。

同时数据表其实还有一些**隐藏的属性**，比如每一行的事务 id，所以**每一行数据可能会有多个版本**，每一个修改过它的事务都会有一行，并且还会有**关联的 undo 日志**，表示这个操作原来的数据是什么，可以用它做回滚。

那么为什么要这么做？

因为如果我们直接把数据修改了，那么其他事务就用不了原先的值了，违反了事务的一致性。

那么一个事务读取某一行的数据到底返回什么结果呢？

取决于隔离级别，如果是 Read Committed，那么返回的是**最新的事务的提交值**，所以未提交的事务修改的值是不会读到的，这就是 Read Committed 实现的原理。

如果是 Read Repeatable 级别，那么只能返回发起时间比当前事务早的事务的提交值，和比当前事务晚的删除事务删除的值。这其实就是 MVCC 方式。

##### undo log

undo log 中存储的是老版本数据。假设修改表中 id=2 的行数据，把 Name=‘B’ 修改为 Name = ‘B2’ ，那么 undo 日志就会用来存放 Name=‘B’ 的记录，如果这个修改出现异常，可以使用 undo 日志来实现回滚操作，保证事务的一致性。

当一个旧的事务需要读取数据时，为了能读取到老版本的数据，需要顺着 undo 链找到满足其可见性的记录。当版本链很长时，通常可以认为这是个比较耗时的操作。

假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。

![](/Users/lidongyue/codes/GitHub/arthur-dy-lee-note/interview/pics/transaction_isolation2.jpg)

当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。

如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。

另外，在回滚段中的 undo log 分为: insert undo log 和 update undo log：

- insert undo log : 事务对 insert 新记录时产生的 undolog，只在事务回滚时需要，并且在事务提交后就可以立即丢弃。（谁会对刚插入的数据有可见性需求呢！！）
- update undo log : 事务对记录进行 delete 和 update 操作时产生的 undo log。不仅在事务回滚时需要，一致性读也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被 purge 线程删除。

**不可重复读和幻读的区别**

很多人容易搞混不可重复读和幻读，确实这两者有些相似。但不可重复读重点在于update和delete，而幻读的重点在于insert。

如果使用锁机制来实现这两种隔离级别，在可重复读中，该sql第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据，就可以实现可重复 读了。但这种方法却无法锁住insert的数据，所以当事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会 发现莫名其妙多了一条之前没有的数据，这就是幻读，不能通过行锁来避免。需要Serializable隔离级别或间隙锁。











#### 参考

[事物级别，不可重复读和幻读的区别](https://blog.csdn.net/qq_35433593/article/details/86094028)





